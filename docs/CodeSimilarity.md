# csim

This project analyzes structural similarity between Python source code using
ANTLR4-generated ASTs and Zhang–Shasha Tree Edit Distance (ZSS).

For next versions, support for additional programming languages will be added.

## AST Normalization and ZSS Tree Construction

This project compares Python source code by measuring **structural similarity**
between normalized Abstract Syntax Trees (ASTs).
The ASTs are generated using **ANTLR4** and compared using
**Zhang–Shasha Tree Edit Distance (ZSS)**.

### Version Baseline
- **Python:** 3.9–3.12 (recommended 3.11)
- **ANTLR4 Python Runtime:** 4.13.2
- **zss:** 1.2.0

To ensure **experimental reproducibility, efficiency, and traceability**,
the following design decisions are applied.

### Rule and Token Exclusion Strategy

Instead of relying on rule names or regular expressions, this project
exclusively uses:

- `ruleIndex` for parser rules
- `token.type` for lexer tokens

Both identifiers are **numeric constants generated by ANTLR**, which guarantees:

- O(1) comparisons
- Independence from rule names
- Robustness across grammar or version changes

### Collapsed Parser Rules
Collapsed rules are defined using explicit sets of rule indices:

```python
COLLAPSED_RULE_INDICES: set[int]
```

These rules are collapsed to reduce AST depth and noise. In the current implementation, when a collapsed rule is visited it is replaced by a single node labeled with its `ruleIndex` and its children are not traversed. This creates a compact representation for list-like or syntactically noisy constructs.

#### Excluded Lexer Tokens

Excluded tokens are defined as:

```python
EXCLUDED_TOKEN_TYPES: set[int]
```

Tokens are excluded when they do **not contribute meaningful semantic or
structural information**.

### Control Flow Equivalence

To enable comparison of structurally equivalent control flow constructs regardless of their syntactic representation, certain rules are mapped to common labels. This allows, for example, `for` and `while` loops to be treated as equivalent "LOOP" constructs during comparison.

Control flow equivalence is defined as:

```python
CONTROL_EQUIVALENCE_RULE_INDICES: dict[int, str]
```

This mapping replaces specific rule indices with semantic labels during tree construction. For example:

```python
CONTROL_EQUIVALENCE_RULE_INDICES = {
    PythonParser.RULE_for_stmt: "LOOP",
    PythonParser.RULE_while_stmt: "LOOP",
}
```

This normalization reduces false differences when comparing code that uses different loop constructs but implements the same logical structure.

### Selective Child Exclusion

Some rules contain children that do not contribute meaningful structural information for comparison purposes. These children can be selectively excluded to reduce noise in the AST.

Excluded children are defined as:

```python
EXCLUDE_CHILDRENS_FROM_RULE: dict[int, list[int]]
```

The dictionary maps parent rule indices to lists of child token types that should be excluded.

In this example, the `IN` keyword and variable `NAME` tokens are excluded from `for` statements because they represent syntactic noise rather than structural significance. The iteration pattern itself is preserved while removing language-specific tokens that don't affect the logical structure. 

### Augmented Assignment Normalization

Augmented assignments are rewritten into a normalized form so equivalent operations compare identically. For example, `i += k` is treated as `i = i + k`. This reduces superficial differences in code that uses different assignment syntax.

The normalization uses a mapping from augmented assignment operators to the parser rule and operator token that represent the equivalent binary operation:

```python
ASSIGN_OP_NORMALIZED: dict[str, list[int]]
```

### ZSS Tree Construction

The normalized tree is constructed using an **ANTLR Visitor**.

Each node in the resulting ZSS tree represents one of:

- A **parser rule** (`ruleIndex`)
- A **relevant lexer token** (`token.type`)
- A **control flow equivalence label** (string, e.g., "LOOP")

All nodes are labeled using **integer identifiers** or **string labels** for semantically equivalent constructs.

To prevent collision between rule indices and token types, token types are offset by a constant value:

```python
TOKEN_TYPE_OFFSET = 1000
```

During tree construction and pruning, the following transformations are applied:

1. **Control flow equivalence mapping**: Rules defined in `CONTROL_EQUIVALENCE_RULE_INDICES` are replaced with their semantic labels.
2. **Selective child exclusion**: Children specified in `EXCLUDE_CHILDRENS_FROM_RULE` are filtered out during traversal.
3. **Hash-based pruning**: Subtrees of rules in `HASHED_RULE_INDICES` are hashed to create compact representations.

### Hash-Based Pruning
To optimize tree size while preserving essential structure, a hash-based pruning strategy is employed.
The pruning process involves:
1. **Hashing Subtrees:** Each subtree is hashed to create a unique identifier.
2. **Identifying Redundant Subtrees:** Subtrees with identical hashes are identified as redundant.
3. **Pruning Redundant Subtrees:** Redundant subtrees are pruned from the AST, retaining only one instance of each unique subtree.

Rules whose subtrees are subject to hashing for pruning are defined as:

```python
HASHED_RULE_INDICES: set[int]
```

### Tree Edit Distance Configuration

Similarity is computed using **Zhang–Shasha Tree Edit Distance (ZSS)**.

Recommended base costs:

| Operation | Cost |
|---------|------|
| Insert  | 1 |
| Delete | 1 |
| Update (same label) | 0 |
| Update (different label) | 1 |

### Similarity Calculation
Similarity is calculated as:

```python
def SimilarityIndex(d, T1, T2):
    # If edit distance exceeds the bound given by max(T1, T2),
    # normalize by total nodes to keep the value non-negative.
    if d > max(T1, T2):
        s_alt = 1 - (d / max(T1 + T2, 1))
        s_alt = round(s_alt, 2)
        return s_alt

    m = max(T1, T2)
    s = 1 - (d / m)
    s = round(s, 2)
    return s
```

Where:
- `d`: Tree edit distance between the two ASTs
- `T1`: Number of nodes in the first AST
- `T2`: Number of nodes in the second AST

The similarity index typically ranges from `0.0` (completely different) to `1.0` (identical).


### Experimental Traceability

These design choices provide:

- Deterministic and reproducible comparisons
- Clear justification of AST transformations
- Fine-grained control over abstraction levels
- Semantic equivalence through control flow normalization
- Reduced noise through targeted child exclusion
- Language-agnostic extension points for new languages
