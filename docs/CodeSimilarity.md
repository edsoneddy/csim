# csim

This project analyzes structural similarity between Python source code using
ANTLR4-generated ASTs and Zhang–Shasha Tree Edit Distance (ZSS).

For next versions, support for additional programming languages will be added.

## AST Normalization and ZSS Tree Construction

This project compares Python source code by measuring **structural similarity**
between normalized Abstract Syntax Trees (ASTs).
The ASTs are generated using **ANTLR4** and compared using
**Zhang–Shasha Tree Edit Distance (ZSS)**.

### Version Baseline
- **Python:** 3.9–3.12 (recommended 3.11)
- **ANTLR4 Python Runtime:** 4.13.2
- **zss:** 1.2.0

To ensure **experimental reproducibility, efficiency, and traceability**,
the following design decisions are applied.

### Rule and Token Exclusion Strategy

Instead of relying on rule names or regular expressions, this project
exclusively uses:

- `ruleIndex` for parser rules
- `token.type` for lexer tokens

Both identifiers are **numeric constants generated by ANTLR**, which guarantees:

- O(1) comparisons
- Independence from rule names
- Robustness across grammar or version changes

### Collapsed Parser Rules
Collapsed rules are defined using explicit sets of rule indices:

```python
COLLAPSED_RULE_INDICES: set[int]
```

These rules are collapsed to reduce AST depth and noise. In the current implementation, when a collapsed rule is visited it is replaced by a single node labeled with its `ruleIndex` and its children are not traversed. This creates a compact representation for list-like or syntactically noisy constructs.

#### Excluded Parser Rules and Lexer Tokens

Excluded rules are defined as:

```python
EXCLUDED_RULE_INDICES: set[int]
```

Rules are excluded when they do **not contribute meaningful semantic or
structural information**.

Excluded tokens are defined as:

```python
EXCLUDED_TOKEN_TYPES: set[int]
```

Tokens are excluded when they do **not contribute meaningful semantic or
structural information**. 


### ZSS Tree Construction

The normalized tree is constructed using an **ANTLR Visitor**.

Each node in the resulting ZSS tree represents one of:

- A **parser rule** (`ruleIndex`)
- A **relevant lexer token** (`token.type`)

All nodes are labeled using **integer identifiers only**.

For preventing use the same integer for both rule and token nodes, token types are offset by a constant value.

```python
TOKEN_TYPE_OFFSET = 1000
```

### Hash-Based Pruning
To optimize tree size while preserving essential structure, a hash-based pruning strategy is employed.
The pruning process involves:
1. **Hashing Subtrees:** Each subtree is hashed to create a unique identifier.
2. **Identifying Redundant Subtrees:** Subtrees with identical hashes are identified as redundant.
3. **Pruning Redundant Subtrees:** Redundant subtrees are pruned from the AST, retaining only one instance of each unique subtree.

Rules whose subtrees are subject to hashing for pruning are defined as:

```python
HASHED_RULE_INDICES: set[int]
```

### Tree Edit Distance Configuration

Similarity is computed using **Zhang–Shasha Tree Edit Distance (ZSS)**.

Recommended base costs:

| Operation | Cost |
|---------|------|
| Insert  | 1 |
| Delete | 1 |
| Update (same label) | 0 |
| Update (different label) | 1 |

### Similarity Calculation
Similarity is calculated as:

```python
def SimilarityIndex(d, T1, T2):
    # If edit distance exceeds the bound given by max(T1, T2),
    # normalize by total nodes to keep the value non-negative.
    if d > max(T1, T2):
        s_alt = 1 - (d / max(T1 + T2, 1))
        s_alt = round(s_alt, 2)
        return s_alt

    m = max(T1, T2)
    s = 1 - (d / m)
    s = round(s, 2)
    return s
```

Where:
- `d`: Tree edit distance between the two ASTs
- `T1`: Number of nodes in the first AST
- `T2`: Number of nodes in the second AST

The similarity index typically ranges from `0.0` (completely different) to `1.0` (identical).


### Experimental Traceability

These design choices provide:

- Deterministic and reproducible comparisons
- Clear justification of AST transformations
- Fine-grained control over abstraction levels
